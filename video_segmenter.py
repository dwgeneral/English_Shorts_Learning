#!/usr/bin/env python3
"""
æ™ºèƒ½è§†é¢‘åˆ†æ®µå·¥å…·
åŸºäºVTTå­—å¹•å†…å®¹ä½¿ç”¨LLMåˆ†æåˆé€‚çš„æ–­ç‚¹ï¼Œç„¶åç”¨ffmpegè¿›è¡Œåˆ†æ®µ
"""

import re
import os
import sys
import json
import argparse
import subprocess
from typing import List, Dict, Tuple
from datetime import datetime, timedelta
import requests

class VTTParser:
    """VTTå­—å¹•æ–‡ä»¶è§£æå™¨"""
    
    def __init__(self, vtt_file: str):
        self.vtt_file = vtt_file
        self.subtitles = []
        
    def parse(self) -> List[Dict]:
        """è§£æVTTæ–‡ä»¶ï¼Œè¿”å›å­—å¹•åˆ—è¡¨"""
        with open(self.vtt_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åŒ¹é…æ—¶é—´æˆ³å’Œæ–‡æœ¬çš„æ­£åˆ™è¡¨è¾¾å¼
        pattern = r'(\d{2}:\d{2}:\d{2}\.\d{3}) --> (\d{2}:\d{2}:\d{2}\.\d{3}).*?\n(.*?)(?=\n\n|\n\d{2}:|$)'
        matches = re.findall(pattern, content, re.DOTALL)
        
        for match in matches:
            start_time = match[0]
            end_time = match[1]
            text = match[2].strip()
            
            # æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤HTMLæ ‡ç­¾å’Œæ—¶é—´æˆ³
            text = re.sub(r'<[^>]+>', '', text)
            text = re.sub(r'\d{2}:\d{2}:\d{2}\.\d{3}', '', text)
            text = re.sub(r'<c>|</c>', '', text)
            text = re.sub(r'\s+', ' ', text).strip()
            
            if text and text not in ['[Music]', ' ']:
                self.subtitles.append({
                    'start': start_time,
                    'end': end_time,
                    'text': text
                })
        
        return self.subtitles
    
    def time_to_seconds(self, time_str: str) -> float:
        """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºç§’æ•°"""
        h, m, s = time_str.split(':')
        return int(h) * 3600 + int(m) * 60 + float(s)
    
    def seconds_to_time(self, seconds: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºæ—¶é—´å­—ç¬¦ä¸²"""
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = seconds % 60
        return f"{h:02d}:{m:02d}:{s:06.3f}"

class LLMAnalyzer:
    """ä½¿ç”¨LLMåˆ†æå­—å¹•å†…å®¹æ‰¾åˆ°åˆé€‚çš„åˆ†æ®µç‚¹"""
    
    def __init__(self, api_key: str = None, model: str = "gpt-3.5-turbo"):
        self.api_key = api_key
        self.model = model
        
    def analyze_segments(self, subtitles: List[Dict], target_duration: int = 35) -> List[float]:
        """åˆ†æå­—å¹•å†…å®¹ï¼Œè¿”å›åˆ†æ®µæ—¶é—´ç‚¹ï¼ˆç§’ï¼‰"""
        # å°†å­—å¹•æ–‡æœ¬åˆå¹¶ä¸ºè¿ç»­æ–‡æœ¬
        full_text = ""
        time_mapping = []
        
        for sub in subtitles:
            start_seconds = self._time_to_seconds(sub['start'])
            full_text += f"[{sub['start']}] {sub['text']} "
            time_mapping.append((start_seconds, len(full_text)))
        
        # å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†æ®µ
        if not self.api_key:
            return self._rule_based_segmentation(subtitles, target_duration)
        
        # ä½¿ç”¨LLMåˆ†æ
        try:
            return self._llm_based_segmentation(full_text, time_mapping, target_duration)
        except Exception as e:
            print(f"LLMåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†æ®µ: {e}")
            return self._rule_based_segmentation(subtitles, target_duration)
    
    def _time_to_seconds(self, time_str: str) -> float:
        """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºç§’æ•°"""
        h, m, s = time_str.split(':')
        return int(h) * 3600 + int(m) * 60 + float(s)
    
    def _rule_based_segmentation(self, subtitles: List[Dict], target_duration: int) -> List[float]:
        """åŸºäºè§„åˆ™çš„åˆ†æ®µæ–¹æ³•"""
        segments = []
        current_start = 0
        
        for i, sub in enumerate(subtitles):
            current_time = self._time_to_seconds(sub['start'])
            
            # å¦‚æœå½“å‰æ®µè½å·²ç»è¾¾åˆ°ç›®æ ‡æ—¶é•¿
            if current_time - current_start >= target_duration:
                # å¯»æ‰¾åˆé€‚çš„æ–­ç‚¹ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·åï¼‰
                text = sub['text']
                if any(punct in text for punct in ['.', '?', '!', 'ã€‚', 'ï¼Ÿ', 'ï¼']):
                    segments.append(current_time)
                    current_start = current_time
                # æˆ–è€…åœ¨åœé¡¿è¾ƒé•¿çš„åœ°æ–¹åˆ†æ®µ
                elif i < len(subtitles) - 1:
                    next_start = self._time_to_seconds(subtitles[i + 1]['start'])
                    current_end = self._time_to_seconds(sub['end'])
                    if next_start - current_end > 1.0:  # åœé¡¿è¶…è¿‡1ç§’
                        segments.append(current_time)
                        current_start = current_time
        
        return segments
    
    def _llm_based_segmentation(self, text: str, time_mapping: List[Tuple], target_duration: int) -> List[float]:
        """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ®µ"""
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹å¸¦æ—¶é—´æˆ³çš„è§†é¢‘å­—å¹•å†…å®¹ï¼Œæ‰¾å‡ºåˆé€‚çš„åˆ†æ®µç‚¹ã€‚æ¯æ®µåº”è¯¥åœ¨{target_duration-5}åˆ°{target_duration+5}ç§’ä¹‹é—´ã€‚

åˆ†æ®µåŸåˆ™ï¼š
1. åœ¨è‡ªç„¶çš„è¯é¢˜è½¬æ¢ç‚¹åˆ†æ®µ
2. åœ¨å®Œæ•´å¥å­ç»“æŸååˆ†æ®µ
3. é¿å…åœ¨å¥å­ä¸­é—´åˆ†æ®µ
4. è€ƒè™‘å†…å®¹çš„é€»è¾‘è¿è´¯æ€§

å­—å¹•å†…å®¹ï¼š
{text[:2000]}...

è¯·è¿”å›JSONæ ¼å¼çš„åˆ†æ®µæ—¶é—´ç‚¹ï¼ˆæ ¼å¼ï¼šHH:MM:SS.mmmï¼‰ï¼Œä¾‹å¦‚ï¼š
{{"segments": ["00:00:35.000", "00:01:10.000", "00:01:45.000"]}}
"""
        
        # è¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºä¸åŒçš„å…è´¹LLM API
        # ç¤ºä¾‹ä½¿ç”¨OpenAI APIï¼ˆéœ€è¦APIå¯†é’¥ï¼‰
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [
                {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘ç¼–è¾‘åŠ©æ‰‹ï¼Œæ“…é•¿åˆ†æå†…å®¹å¹¶æ‰¾åˆ°åˆé€‚çš„åˆ†æ®µç‚¹ã€‚'},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.3
        }
        
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # è§£æJSONå“åº”
            try:
                segments_data = json.loads(content)
                segments = []
                for time_str in segments_data.get('segments', []):
                    segments.append(self._time_to_seconds(time_str))
                return segments
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–æ—¶é—´
                time_pattern = r'\d{2}:\d{2}:\d{2}\.\d{3}'
                times = re.findall(time_pattern, content)
                return [self._time_to_seconds(t) for t in times]
        
        raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")

class VideoSegmenter:
    """è§†é¢‘åˆ†æ®µå™¨"""
    
    def __init__(self, video_file: str, output_dir: str = "segments"):
        self.video_file = video_file
        self.output_dir = output_dir
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
    
    def segment_video(self, breakpoints: List[float]) -> List[str]:
        """æ ¹æ®æ–­ç‚¹åˆ†æ®µè§†é¢‘"""
        output_files = []
        
        # æ·»åŠ å¼€å§‹å’Œç»“æŸæ—¶é—´ç‚¹
        all_points = [0.0] + sorted(breakpoints) + [self._get_video_duration()]
        
        for i in range(len(all_points) - 1):
            start_time = all_points[i]
            end_time = all_points[i + 1]
            duration = end_time - start_time
            
            # è·³è¿‡å¤ªçŸ­çš„ç‰‡æ®µ
            if duration < 10:
                continue
            
            output_file = os.path.join(self.output_dir, f"segment_{i+1:03d}.mp4")
            
            cmd = [
                'ffmpeg', '-y',
                '-i', self.video_file,
                '-ss', str(start_time),
                '-t', str(duration),
                '-c', 'copy',
                output_file
            ]
            
            print(f"æ­£åœ¨ç”Ÿæˆç‰‡æ®µ {i+1}: {start_time:.1f}s - {end_time:.1f}s ({duration:.1f}s)")
            
            try:
                subprocess.run(cmd, check=True, capture_output=True)
                output_files.append(output_file)
                print(f"âœ“ ç”ŸæˆæˆåŠŸ: {output_file}")
            except subprocess.CalledProcessError as e:
                print(f"âœ— ç”Ÿæˆå¤±è´¥: {e}")
        
        return output_files
    
    def _get_video_duration(self) -> float:
        """è·å–è§†é¢‘æ€»æ—¶é•¿"""
        cmd = [
            'ffprobe', '-v', 'quiet',
            '-print_format', 'json',
            '-show_format',
            self.video_file
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            data = json.loads(result.stdout)
            return float(data['format']['duration'])
        except Exception:
            # å¦‚æœffprobeå¤±è´¥ï¼Œä»VTTæ–‡ä»¶ä¼°ç®—
            return 24 * 60  # é»˜è®¤24åˆ†é’Ÿ

def main():
    parser = argparse.ArgumentParser(description='æ™ºèƒ½è§†é¢‘åˆ†æ®µå·¥å…·')
    parser.add_argument('video', help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('vtt', help='VTTå­—å¹•æ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', default='segments', help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: segmentsï¼‰')
    parser.add_argument('-d', '--duration', type=int, default=35, help='ç›®æ ‡ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼Œé»˜è®¤: 35ï¼‰')
    parser.add_argument('--api-key', help='LLM APIå¯†é’¥ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨åŸºäºè§„åˆ™çš„åˆ†æ®µï¼‰')
    parser.add_argument('--model', default='gpt-3.5-turbo', help='LLMæ¨¡å‹åç§°ï¼ˆé»˜è®¤: gpt-3.5-turboï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='ä»…åˆ†æåˆ†æ®µç‚¹ï¼Œä¸å®é™…åˆ†å‰²è§†é¢‘')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.video):
        print(f"é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video}")
        sys.exit(1)
    
    if not os.path.exists(args.vtt):
        print(f"é”™è¯¯: VTTæ–‡ä»¶ä¸å­˜åœ¨: {args.vtt}")
        sys.exit(1)
    
    # æ£€æŸ¥ffmpegæ˜¯å¦å¯ç”¨
    if not args.dry_run:
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            print("é”™è¯¯: æœªæ‰¾åˆ°ffmpegï¼Œè¯·å…ˆå®‰è£…ffmpeg")
            sys.exit(1)
    
    print("ğŸ¬ å¼€å§‹æ™ºèƒ½è§†é¢‘åˆ†æ®µ...")
    
    # è§£æVTTæ–‡ä»¶
    print("ğŸ“ è§£æå­—å¹•æ–‡ä»¶...")
    parser_vtt = VTTParser(args.vtt)
    subtitles = parser_vtt.parse()
    print(f"âœ“ è§£æå®Œæˆï¼Œå…± {len(subtitles)} æ¡å­—å¹•")
    
    # åˆ†æåˆ†æ®µç‚¹
    print("ğŸ¤– åˆ†æåˆ†æ®µç‚¹...")
    analyzer = LLMAnalyzer(args.api_key, args.model)
    breakpoints = analyzer.analyze_segments(subtitles, args.duration)
    print(f"âœ“ åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(breakpoints)} ä¸ªåˆ†æ®µç‚¹")
    
    # æ˜¾ç¤ºåˆ†æ®µä¿¡æ¯
    print("\nğŸ“Š åˆ†æ®µä¿¡æ¯:")
    all_points = [0.0] + sorted(breakpoints)
    for i in range(len(all_points)):
        start = all_points[i]
        end = all_points[i + 1] if i + 1 < len(all_points) else parser_vtt.time_to_seconds(subtitles[-1]['end'])
        duration = end - start
        print(f"  ç‰‡æ®µ {i+1}: {parser_vtt.seconds_to_time(start)} - {parser_vtt.seconds_to_time(end)} ({duration:.1f}s)")
    
    if args.dry_run:
        print("\nğŸ” ä»…åˆ†ææ¨¡å¼ï¼Œæœªç”Ÿæˆè§†é¢‘ç‰‡æ®µ")
        return
    
    # åˆ†å‰²è§†é¢‘
    print("\nâœ‚ï¸ å¼€å§‹åˆ†å‰²è§†é¢‘...")
    segmenter = VideoSegmenter(args.video, args.output)
    output_files = segmenter.segment_video(breakpoints)
    
    print(f"\nğŸ‰ åˆ†å‰²å®Œæˆï¼ç”Ÿæˆäº† {len(output_files)} ä¸ªè§†é¢‘ç‰‡æ®µ:")
    for file in output_files:
        print(f"  - {file}")

if __name__ == '__main__':
    main()